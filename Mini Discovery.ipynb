{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import io\n",
    "import binvox_rw\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv3DTranspose, Concatenate, Dropout\n",
    "from tensorflow.keras.layers import MaxPool2D, UpSampling3D, Reshape, Flatten, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Add, Dense, MaxPool3D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.losses import Loss, BinaryCrossentropy, BinaryFocalCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryIoU\n",
    "from tensorflow_addons.losses import GIoULoss\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(voxin):\n",
    "    f = np.squeeze(np.max(voxin, axis=(2, 1)))\n",
    "    s = np.squeeze(np.max(voxin, axis=(2, 0)))\n",
    "    t = np.squeeze(np.max(voxin, axis=(1, 0)))\n",
    "\n",
    "    nzf = np.sum(f == 0) \n",
    "    nzs = np.sum(s == 0)\n",
    "    nzt = np.sum(t == 0)\n",
    "\n",
    "    i_f = np.argmax(f)\n",
    "    l_f = np.sum(f > 0)\n",
    "    i_s = np.argmax(s)\n",
    "    l_s = np.sum(s > 0)\n",
    "    i_t = np.argmax(t)\n",
    "    l_t = np.sum(t > 0)\n",
    "\n",
    "    zfl = np.floor(nzf/2.0).astype(int)\n",
    "    zfr = nzf - zfl\n",
    "    zsl = np.floor(nzs/2.0).astype(int)\n",
    "    zsr = nzs - zsl\n",
    "    ztl = np.floor(nzt/2.0).astype(int)\n",
    "    ztr = nzt - ztl  \n",
    "\n",
    "    voxout = np.zeros_like(voxin)\n",
    "    voxout[zfl:128-zfr, zsl:128-zsr, ztl:128-ztr] = voxin[i_f:i_f+l_f, i_s:i_s+l_s, i_t:i_t+l_t,]\n",
    "    return voxout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class voxel_gen(Sequence):\n",
    "    def __init__(self, y_set, batch_size=32, dim_image=(512, 512, 3), dim_voxel=(128, 128, 128)):\n",
    "        self.y = y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.dim_voxel = dim_voxel\n",
    "        self.dim_image = dim_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        y_set_temp = self.y[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X, Y = self.__data_generation(y_set_temp)\n",
    "        return [X, Y]\n",
    "    \n",
    "    def __data_generation(self, y_set_temp):\n",
    "        X0 = np.empty((self.batch_size, *self.dim_image))\n",
    "        X1 = np.empty((self.batch_size, *self.dim_image))\n",
    "        X2 = np.empty((self.batch_size, *self.dim_image))\n",
    "        X3 = np.empty((self.batch_size, *self.dim_image))\n",
    "        Y = np.empty((self.batch_size, *self.dim_voxel, 1))\n",
    "\n",
    "        for i, stem in enumerate(y_set_temp):\n",
    "            view0 = f\"models/models-screenshots/view0/data/{stem}-00.png\"\n",
    "            view1 = f\"models/models-screenshots/view1/data/{stem}-01.png\"\n",
    "            view2 = f\"models/models-screenshots/view2/data/{stem}-02.png\"\n",
    "            view3 = f\"models/models-screenshots/view3/data/{stem}-03.png\"\n",
    "            X0[i,] = np.array(Image.open(view0))[:, :, 0:3]\n",
    "            X1[i,] = np.array(Image.open(view1))[:, :, 0:3]\n",
    "            X2[i,] = np.array(Image.open(view2))[:, :, 0:3]\n",
    "            X3[i,] = np.array(Image.open(view3))[:, :, 0:3]\n",
    "            vox = f\"models/models-binvox-solid/data/{stem}.binvox\"\n",
    "            with open(str(vox), 'rb') as f:\n",
    "                model = binvox_rw.read_as_3d_array(f)\n",
    "            Y[i,] = np.expand_dims(center(model.data), axis=-1) * 1\n",
    "    \n",
    "        return [[X0, X1, X2, X3], Y]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.y = random.shuffle(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customGen(batch_size=32):\n",
    "    voxels = Path(\"models/models-binvox-solid/data\")\n",
    "    fvoxels = [f.stem for f in voxels.iterdir() if f.is_file()]\n",
    "    out = voxel_gen(fvoxels, batch_size)\n",
    "    while True:\n",
    "        for x, y in out:\n",
    "            yield [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_decode():\n",
    "    inview0 = tf.keras.applications.resnet_v2.preprocess_input(Input(shape=(512, 512, 3), name='view0'))\n",
    "    inview1 = tf.keras.applications.resnet_v2.preprocess_input(Input(shape=(512, 512, 3), name='view1'))\n",
    "    inview2 = tf.keras.applications.resnet_v2.preprocess_input(Input(shape=(512, 512, 3), name='view2'))\n",
    "    inview3 = tf.keras.applications.resnet_v2.preprocess_input(Input(shape=(512, 512, 3), name='view3'))\n",
    "   \n",
    "    encoder = Sequential([\n",
    "            Conv2D(32, 3, activation='relu', padding='same'),\n",
    "            MaxPool2D((4, 4)),\n",
    "            Conv2D(32, 5, activation='relu', padding='same'),\n",
    "            MaxPool2D((4, 4)),\n",
    "            Conv2D(64, 7, activation='relu', padding='same'),\n",
    "            MaxPool2D((4, 4)),\n",
    "            Conv2D(64, 5, activation='relu', padding='same'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Conv2D(128, 3, activation='relu', padding='same'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Conv2D(128, 3, activation='relu', padding='same'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Reshape((-1, 1)),\n",
    "    ], name='encoder')\n",
    "    \n",
    "    x0 = encoder(inview0)\n",
    "    x1 = encoder(inview1)\n",
    "    x2 = encoder(inview2)\n",
    "    x3 = encoder(inview3)\n",
    "    \n",
    "    combined = Concatenate(axis=-1)([x0, x1, x2, x3])\n",
    "    \n",
    "    FC = Sequential([\n",
    "        Dropout(rate=0.5, noise_shape=[None, 1, 4]),\n",
    "        Flatten(),\n",
    "        Dense(256),\n",
    "        Dense(1024),\n",
    "        Reshape((2, 2, 2, 128))\n",
    "    ], name='FC')(combined)\n",
    "    \n",
    "    decoder = Sequential([\n",
    "            Conv3DTranspose(32, 5, activation='relu', padding='same'),\n",
    "            UpSampling3D(4),\n",
    "            Conv3DTranspose(16, 3, activation='relu', padding='same'),\n",
    "            UpSampling3D(2),\n",
    "            Conv3DTranspose(8, 3, activation='relu', padding='same'),\n",
    "            UpSampling3D(2),\n",
    "            Conv3DTranspose(4, 3, activation='relu', padding='same'),\n",
    "            UpSampling3D(2),\n",
    "            Conv3DTranspose(2, 3, activation='relu', padding='same'),\n",
    "            UpSampling3D(2)\n",
    "    ], name='decoder')(FC)\n",
    "    \n",
    "    out = Conv3DTranspose(1, 3, activation='sigmoid', padding='same')(decoder)\n",
    "    \n",
    "    return Model(inputs=[inview0, inview1, inview2, inview3], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = encode_decode()\n",
    "model.summary(line_length=118, positions=[.38, .66, .75, 1.], expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSFCE(Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        bce = BinaryCrossentropy()\n",
    "        P = tf.reshape(tf.convert_to_tensor(y_pred), [-1])\n",
    "        T = tf.reshape(tf.cast(y_true, y_pred.dtype), [-1])\n",
    "        Pmask = tf.math.greater(T, tf.constant(0.5, dtype=tf.float32))\n",
    "        Nmask = tf.math.less(T, tf.constant(0.5, dtype=tf.float32))\n",
    "        Vp = tf.boolean_mask(T, Pmask)\n",
    "        Vp_pred = tf.boolean_mask(P, Pmask)\n",
    "        Vn = tf.boolean_mask(T, Nmask)\n",
    "        Vn_pred = tf.boolean_mask(P, Nmask)\n",
    "        FNCE = bfce(Vp, Vp_pred)\n",
    "        FPCE = bfce(Vn, Vn_pred)\n",
    "        return tf.reduce_mean([tf.pow(FPCE, 2), tf.pow(FNCE, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "class MSFFCE(Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        bfce = BinaryFocalCrossentropy()\n",
    "        P = tf.reshape(tf.convert_to_tensor(y_pred), [-1])\n",
    "        T = tf.reshape(tf.cast(y_true, y_pred.dtype), [-1])\n",
    "        Pmask = tf.math.greater(T, tf.constant(0.5, dtype=tf.float32))\n",
    "        Nmask = tf.math.less(T, tf.constant(0.5, dtype=tf.float32))\n",
    "        Vp = tf.boolean_mask(T, Pmask)\n",
    "        Vp_pred = tf.boolean_mask(P, Pmask)\n",
    "        Vn = tf.boolean_mask(T, Nmask)\n",
    "        Vn_pred = tf.boolean_mask(P, Nmask)\n",
    "        FNCE = bfce(Vp, Vp_pred)\n",
    "        FPCE = bfce(Vn, Vn_pred)\n",
    "        return tf.reduce_mean([tf.pow(FPCE, 2), tf.pow(FNCE, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIoU(Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        #todo\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss = MSFFCE()\n",
    "#BinaryCrossentropy(), BinaryFocalCrossentropy(), MSFCE(), MSFFCE() have been tested to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=[BinaryIoU()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(customGen(batch_size=batch_size), epochs=1,\n",
    "                    steps_per_epoch=tf.math.ceil(11694 / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['binary_io_u'])\n",
    "plt.title('model IOU')\n",
    "plt.ylabel('IOU')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels = Path(\"models/models-binvox-solid/data\")\n",
    "fvoxels = [f.stem for f in voxels.iterdir() if f.is_file()]\n",
    "sample = np.random.randint(11695, size=1, dtype=np.int64)[0]\n",
    "print(sample)\n",
    "stem = fvoxels[sample]\n",
    "view0 = f\"models/models-screenshots/view0/data/{stem}-00.png\"\n",
    "view1 = f\"models/models-screenshots/view1/data/{stem}-01.png\"\n",
    "view2 = f\"models/models-screenshots/view2/data/{stem}-02.png\"\n",
    "view3 = f\"models/models-screenshots/view3/data/{stem}-03.png\"\n",
    "X0 = np.expand_dims(np.array(Image.open(view0))[:, :, 0:3], axis=0)\n",
    "X1 = np.expand_dims(np.array(Image.open(view1))[:, :, 0:3], axis=0)\n",
    "X2 = np.expand_dims(np.array(Image.open(view2))[:, :, 0:3], axis=0)\n",
    "X3 = np.expand_dims(np.array(Image.open(view3))[:, :, 0:3], axis=0)\n",
    "\n",
    "vox = f\"models/models-binvox-solid/data/{stem}.binvox\"\n",
    "with open(str(vox), 'rb') as f:\n",
    "    voxel_model = binvox_rw.read_as_3d_array(f)\n",
    "\n",
    "Y = center(voxel_model.data) * 1\n",
    "y = (model([X0, X1, X2, X3], training=False).numpy() > 0.5) * 1\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax1 = plt.subplot2grid((1, 2), (0, 0), projection='3d')\n",
    "ax2 = plt.subplot2grid((1, 2), (0, 1), projection='3d')\n",
    "ax1.voxels(np.squeeze(Y))\n",
    "ax2.voxels(np.squeeze(y))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
