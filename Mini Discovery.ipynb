{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import binvox_rw\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv3DTranspose, Concatenate\n",
    "from tensorflow.keras.layers import MaxPool2D, UpSampling3D, Reshape\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(voxin):\n",
    "    f = np.squeeze(np.max(voxin, axis=(2, 1)))\n",
    "    s = np.squeeze(np.max(voxin, axis=(2, 0)))\n",
    "    t = np.squeeze(np.max(voxin, axis=(1, 0)))\n",
    "\n",
    "    nzf = np.sum(f == 0) \n",
    "    nzs = np.sum(s == 0)\n",
    "    nzt = np.sum(t == 0)\n",
    "\n",
    "    i_f = np.argmax(f)\n",
    "    l_f = np.sum(f > 0)\n",
    "    i_s = np.argmax(s)\n",
    "    l_s = np.sum(s > 0)\n",
    "    i_t = np.argmax(t)\n",
    "    l_t = np.sum(t > 0)\n",
    "\n",
    "    zfl = np.floor(nzf/2.0).astype(int)\n",
    "    zfr = nzf - zfl\n",
    "    zsl = np.floor(nzs/2.0).astype(int)\n",
    "    zsr = nzs - zsl\n",
    "    ztl = np.floor(nzt/2.0).astype(int)\n",
    "    ztr = nzt - ztl  \n",
    "\n",
    "    voxout = np.zeros_like(voxin)\n",
    "    voxout[zfl:128-zfr, zsl:128-zsr, ztl:128-ztr] = voxin[i_f:i_f+l_f, i_s:i_s+l_s, i_t:i_t+l_t,]\n",
    "    return voxout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class voxel_gen(Sequence):\n",
    "    def __init__(self, x_set, batch_size=32, dim=(128,128,128)):\n",
    "        self.x = x_set # path for each dataset : models/models-binvox-solid\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        x_set_temp = self.x[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X = self.__data_generation(x_set_temp)\n",
    "        return X\n",
    "    \n",
    "    def __data_generation(self, x_set_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, 1))\n",
    "\n",
    "        for i, x_set in enumerate(x_set_temp):\n",
    "            # Store sample\n",
    "            with open(str(x_set), 'rb') as f:\n",
    "                model = binvox_rw.read_as_3d_array(f)\n",
    "            X[i,] = np.expand_dims(center(model.data), axis=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customGen(batch_size=32):\n",
    "    gen = ImageDataGenerator(rescale=1/255.)\n",
    "    view0 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view0\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "\n",
    "    view1 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view1\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "\n",
    "    view2 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view2\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "\n",
    "    view3 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view3\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view4 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view4\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view5 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view5\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view6 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view6\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view7 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view7\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view8 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view8\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view9 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view9\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view10 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view10\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view11 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view11\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view12 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view12\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    view13 = gen.flow_from_directory(\n",
    "        \"models/models-screenshots/view13\",\n",
    "        target_size=(512, 512),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    \n",
    "    voxels = Path(\"models/models-binvox-solid/data\")\n",
    "    fvoxels = [f for f in voxels.iterdir() if f.is_file()]\n",
    "    \n",
    "    out = voxel_gen(fvoxels, batch_size)\n",
    "    while True:\n",
    "        for x1, x2, x3, x4,x5, x6, x7, x8,x9, x10, x11, x12,x13,x14, y in zip(view0, view1, view2, view3,view4, view5, view6, view7,view8, view9, view10, view11,view12, view13,out):\n",
    "            yield [x1, x2, x3, x4,x5, x6, x7, x8,x9, x10, x11, x12,x13,x14], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_decode():\n",
    "    inview0 = Input(shape=(512, 512, 3), name='view0')\n",
    "    inview1 = Input(shape=(512, 512, 3), name='view1')\n",
    "    inview2 = Input(shape=(512, 512, 3), name='view2')\n",
    "    inview3 = Input(shape=(512, 512, 3), name='view3')\n",
    "    inview4 = Input(shape=(512, 512, 3), name='view4')\n",
    "    inview5 = Input(shape=(512, 512, 3), name='view5')\n",
    "    inview6 = Input(shape=(512, 512, 3), name='view6')\n",
    "    inview7 = Input(shape=(512, 512, 3), name='view7')\n",
    "    inview8 = Input(shape=(512, 512, 3), name='view8')\n",
    "    inview9 = Input(shape=(512, 512, 3), name='view9')\n",
    "    inview10 = Input(shape=(512, 512, 3), name='view10')\n",
    "    inview11 = Input(shape=(512, 512, 3), name='view11')\n",
    "    inview12 = Input(shape=(512, 512, 3), name='view12')\n",
    "    inview13 = Input(shape=(512, 512, 3), name='view13')\n",
    "   \n",
    "    encoder = Sequential([\n",
    "            Conv2D(32, 7, (2, 2), activation='relu'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Conv2D(32, 5, activation='relu'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Conv2D(64, 3, activation='relu'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Conv2D(64, 3, activation='relu'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Conv2D(128, 3, activation='relu'),\n",
    "            MaxPool2D((2, 2)),\n",
    "            Conv2D(32, 5, activation='relu'),\n",
    "            Reshape((1, 1, 1, -1))\n",
    "    ], name='encoder')\n",
    "    \n",
    "    combined = Concatenate(axis=4)([encoder(inview0), encoder(inview1), encoder(inview2), encoder(inview3), encoder(inview4), encoder(inview5), encoder(inview6), encoder(inview7),encoder(inview8), encoder(inview9), encoder(inview10), encoder(inview11),encoder(inview12), encoder(inview13)])\n",
    "    \n",
    "    decoder = Sequential([\n",
    "            Conv3DTranspose(128, 3, activation='relu'),\n",
    "            UpSampling3D(2),\n",
    "            Conv3DTranspose(64, 3, activation='relu'),\n",
    "            UpSampling3D(2),\n",
    "            Conv3DTranspose(32, 3, activation='relu', padding='same'),\n",
    "            UpSampling3D(2),\n",
    "            Conv3DTranspose(16, 3, activation='relu', padding='same'),\n",
    "            UpSampling3D(2),\n",
    "            Conv3DTranspose(8, 3, activation='relu', padding='same'),\n",
    "            UpSampling3D(2)\n",
    "    ], name='decoder')(combined)\n",
    "    \n",
    "    out = Conv3DTranspose(1, 3, activation='sigmoid', padding='same')(decoder)\n",
    "    \n",
    "    return Model(inputs=[inview0, inview1, inview2, inview3,inview4, inview5, inview6, inview7,inview8, inview9, inview10, inview11,inview12, inview13], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = encode_decode()\n",
    "model.summary(line_length=118, positions=[.38, .66, .75, 1.], expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "class MSFCE(Loss):\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(tf.convert_to_tensor(y_pred), [-1])\n",
    "        y_true = tf.reshape(tf.cast(y_true, y_pred.dtype), [-1])\n",
    "        P = tf.reduce_sum(y_true)\n",
    "        N = 128**3 - P\n",
    "        Pmask = tf.math.equal(y_true, tf.constant(1, dtype=tf.float32))\n",
    "        Nmask = tf.math.equal(y_true, tf.constant(0, dtype=tf.float32))\n",
    "        Vp = tf.boolean_mask(y_true, Pmask)\n",
    "        Vp_pred = tf.boolean_mask(y_pred, Pmask)\n",
    "        Vn = tf.boolean_mask(y_true, Nmask)\n",
    "        Vn_pred = tf.boolean_mask(y_pred, Nmask)\n",
    "        FNCE = -tf.reduce_mean(Vp * tf.math.log(tf.clip_by_value(Vp_pred, 1e-6, 1.)) + (1. - Vp) * tf.math.log(tf.clip_by_value(Vp_pred, 1e-6, 1.)))\n",
    "        FPCE = -tf.reduce_mean(Vn * tf.math.log(tf.clip_by_value(Vn_pred, 1e-6, 1.)) + (1. - Vn) * tf.math.log(tf.clip_by_value(Vn_pred, 1e-6, 1.)))\n",
    "        return FPCE + FNCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = MSFCE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss, metrics=[tf.keras.metrics.CosineSimilarity(), tf.keras.metrics.BinaryIoU()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(customGen(batch_size=2),epochs=5,steps_per_epoch=tf.math.ceil(11694/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
